{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c370c1f0-eca7-4543-8fce-1a77d8e48572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-25 12:36:18 nemo_logging:349] /home/joheras/.local/lib/python3.10/site-packages/hydra/core/plugins.py:225: UserWarning: \n",
      "    \tError importing 'hydra_plugins.hydra_colorlog'.\n",
      "    \tPlugin is incompatible with this Hydra version or buggy.\n",
      "    \tRecommended to uninstall or upgrade plugin.\n",
      "    \t\tImportError : cannot import name 'SearchPathPlugin' from 'hydra.plugins' (/home/joheras/.local/lib/python3.10/site-packages/hydra/plugins/__init__.py)\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 12:36:19.864944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import torch\n",
    "import wget\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning import Trainer\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cd7ebf-e065-4276-a491-f73fd773a050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-25 12:36:21 nlp_overrides:457] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "[NeMo W 2024-04-25 12:36:22 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: ./DataLeo/train.txt\n",
      "    max_seq_length: 128\n",
      "    batch_size: 8\n",
      "    shuffle: true\n",
      "    num_workers: 2\n",
      "    pin_memory: false\n",
      "    drop_last: false\n",
      "    \n",
      "[NeMo W 2024-04-25 12:36:22 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    data_file: ./DataLeo/val.txt\n",
      "    max_seq_length: 128\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 2\n",
      "    pin_memory: false\n",
      "    drop_last: false\n",
      "    \n",
      "[NeMo W 2024-04-25 12:36:22 nlp_overrides:457] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "[NeMo W 2024-04-25 12:36:22 lm_utils:91] bert-base-multilingual-uncased is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n",
      "[NeMo W 2024-04-25 12:36:24 modelPT:251] You tried to register an artifact under config key=language_model.config_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-25 12:36:26 nlp_overrides:755] Model EntityLinkingModel was successfully restored from /home/joheras/CLARA-Med/Normalisation/model-SelfAlignmentPretrainingForMedicalEntityLinking-ClaraMeD-FineTuned/SelfAlignmentPretrainingForMedicalEntityLinking-ClaraMeD-FineTuned.nemo.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel \n",
    "\n",
    "model = nemo_nlp.models.EntityLinkingModel.restore_from('model-SelfAlignmentPretrainingForMedicalEntityLinking-ClaraMeD-FineTuned/SelfAlignmentPretrainingForMedicalEntityLinking-ClaraMeD-FineTuned.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e542afe6-d156-493a-a5c4-129769e86186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5417aae2-3dc4-426b-9e81-953617286142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-25 12:48:17 nemo_logging:349] /tmp/ipykernel_2438651/1043993813.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "      df = pd.read_csv('DataLeo/umls_spa_cui_term_test.txt',sep='\\|\\|',header=None)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('DataLeo/umls_spa_cui_term_test.txt',sep='\\|\\|',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38bb9ab2-b4fe-434c-81c2-bcc37dc539c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['Term','Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9611ab73-9630-4cd6-9671-5dd3f5bbe98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kb = OmegaConf.create({\n",
    "    \"data_file\": os.path.join('DataLeo/umls_spa_cui_term_test.txt'),\n",
    "    \"max_seq_length\": 128,\n",
    "    \"batch_size\": 128,\n",
    "    \"shuffle\": False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b2fce1-80f5-45fc-9c17-1bee0476eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-25 12:36:26 entity_linking_dataset:78] Loaded dataset with 1247174 examples\n"
     ]
    }
   ],
   "source": [
    "test_kb_dataloader = model.setup_dataloader(test_kb, is_index_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8f08f1-5312-4383-8953-cea9e9e8c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get data embeddings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_embeddings(model, dataloader):\n",
    "    embeddings, cids = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, token_type_ids, attention_mask, batch_cids = batch\n",
    "            batch_embeddings = model.forward(input_ids=input_ids.to(device), \n",
    "                                             token_type_ids=token_type_ids.to(device), \n",
    "                                             attention_mask=attention_mask.to(device))\n",
    "\n",
    "            # Accumulate index embeddings and their corresponding IDs\n",
    "            embeddings.extend(batch_embeddings.cpu().detach().numpy())\n",
    "            cids.extend(batch_cids)\n",
    "            \n",
    "    return embeddings, cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f7c1d6-9f57-4f56-8530-bc838b09cf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.14956879615783691,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9744,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f90ccbd94c4578af96cf5d208b15fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "embeddings,_ = get_embeddings(model,test_kb_dataloader)\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2a6be6-3c77-491a-90aa-3dd481482299",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = faiss.IndexFlatL2(768)\n",
    "index = faiss.IndexIVFFlat(quantizer, 768, 50)\n",
    "# index = faiss.index_cpu_to_all_gpus(index)\n",
    "index.train(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bee928d-74f8-45a1-a655-4cf5106851da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015494823455810547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9744,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7580420a5bd40ab81ed4b39b8eb0adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(0, embeddings.shape[0], 128)):\n",
    "    index.add(embeddings[i:i+128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3b72da9-9ffb-4c2c-bffc-bcbd5186252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index,'dataLeo_sap_bert_finetuned_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54f28ae0-4cd8-4641-8a04-297b798c3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901f54a9-da08-4d22-a67d-c728ed9cd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('DataLeo/test_norm_ref.tsv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f400374-4993-407d-be07-1228c6a09546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                nicotina\n",
       "1                                    iPTH\n",
       "2                          fosfato sérico\n",
       "3                                     HDL\n",
       "4                         trombocitopenia\n",
       "5                            hemodiálisis\n",
       "6                            nicotinamida\n",
       "7                         hiperfosfatemia\n",
       "8                            hemodiálisis\n",
       "9    evaluaron la eficacia y la seguridad\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[:,4][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea7c9c60-358f-484b-96fd-c1468f97fa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01341390609741211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 88,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0571e8480144ac5b6896d8c4605a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_names = list(test_data.loc[:,4])\n",
    "bs = 128 # batch size during inference\n",
    "all_embs = []\n",
    "for i in tqdm(np.arange(0, len(all_names), bs)):\n",
    "    \n",
    "    model_input =  model.tokenizer(all_names[i:i+bs],\n",
    "                                   add_special_tokens = True,\n",
    "                                   padding = True,\n",
    "                                   truncation = True,\n",
    "                                   max_length = 512,\n",
    "                                   return_token_type_ids = True,\n",
    "                                   return_attention_mask = True)\n",
    "    \n",
    "    # Pass tokenized input into model\n",
    "    query_emb =  model.forward(input_ids=torch.LongTensor(model_input[\"input_ids\"]).to(device),\n",
    "                               token_type_ids=torch.LongTensor(model_input[\"token_type_ids\"]).to(device),\n",
    "                               attention_mask=torch.LongTensor(model_input[\"attention_mask\"]).to(device))\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_embs.append(query_emb.cpu().detach().numpy())\n",
    "\n",
    "all_embs = np.concatenate(all_embs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4739996-0428-492c-9830-03c6c43c8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f7ec27b-14d7-4f94-ba14-5f34cf9c36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(all_embs, k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b52b6df9-aba1-4536-acd7-59679fd93c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 791489,  791490,  791460,   63875,  850047],\n",
       "       [ 989136,  607973,  988966, 1156852, 1168167],\n",
       "       [ 513638,  514595,  514229,  513907,  871321],\n",
       "       ...,\n",
       "       [1089286,  422003,  422001,  422004,  422009],\n",
       "       [ 860516,  860517,  822751,  341828,  860515],\n",
       "       [1030137, 1030135, 1030136, 1030134, 1091591]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4a709f5-b196-47ed-a396-3d19937ee54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = df['Code'].iloc[I[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b0a5f89-eda6-4b3e-96a5-f60a4a6e181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C0028040', 'C0028050', 'C0028027', 'C0028053', 'C1253423'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ada7a65-3e17-4cac-add3-c1fc8df40388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[:,5][0] in codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bc70913-2814-4de4-9337-5b141b48dc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015668630599975586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81cdbe48cbc4487baccc784f80a1a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aciertosTop1 = 0\n",
    "aciertosTop5 = 0\n",
    "\n",
    "for i,x in tqdm(enumerate(I)):\n",
    "    codes = df['Code'].iloc[x].values\n",
    "    code = test_data.loc[:,5][i]\n",
    "    if (code==codes[0]):\n",
    "        aciertosTop1 += 1\n",
    "    if (code in codes):\n",
    "        aciertosTop5 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820abba5-9077-404e-8fbe-d67a111c4f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Top 1 0.657874\n",
      "Accuracy Top 5 0.791469\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Top 1 %f\" % (aciertosTop1/len(I)))\n",
    "print(\"Accuracy Top 5 %f\" % (aciertosTop5/len(I)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d47eeba-c5c0-4f8b-ae67-5b701d8ddbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_uncert = pd.read_csv('DataLeo/test_norm_ref_with_uncert.tsv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae09ba85-9813-403d-a377-f147fcbbf6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012095451354980469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 91,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb5bb8c805f4ddba57fa3c6d31b7868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_names = list(test_data_uncert.loc[:,4])\n",
    "bs = 128 # batch size during inference\n",
    "all_embs = []\n",
    "for i in tqdm(np.arange(0, len(all_names), bs)):\n",
    "    \n",
    "    model_input =  model.tokenizer(all_names[i:i+bs],\n",
    "                                   add_special_tokens = True,\n",
    "                                   padding = True,\n",
    "                                   truncation = True,\n",
    "                                   max_length = 512,\n",
    "                                   return_token_type_ids = True,\n",
    "                                   return_attention_mask = True)\n",
    "    \n",
    "    # Pass tokenized input into model\n",
    "    query_emb =  model.forward(input_ids=torch.LongTensor(model_input[\"input_ids\"]).to(device),\n",
    "                               token_type_ids=torch.LongTensor(model_input[\"token_type_ids\"]).to(device),\n",
    "                               attention_mask=torch.LongTensor(model_input[\"attention_mask\"]).to(device))\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_embs.append(query_emb.cpu().detach().numpy())\n",
    "\n",
    "all_embs = np.concatenate(all_embs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa82cc3-85da-482e-a098-fe18f4f1f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "067e3281-8848-4f9c-aa44-508eace6d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(all_embs, k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d4763b0-579c-4605-b096-a129babbe191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013814449310302734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f29e2298614132ac8f23161191c3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aciertosTop1 = 0\n",
    "aciertosTop5 = 0\n",
    "\n",
    "for i,x in tqdm(enumerate(I)):\n",
    "    codes = df['Code'].iloc[x].values\n",
    "    code = test_data_uncert.loc[:,5][i]\n",
    "    if (code==codes[0]):\n",
    "        aciertosTop1 += 1\n",
    "    if (code in codes):\n",
    "        aciertosTop5 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfe82102-5142-4d1b-adec-d60b7414e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Top 1 0.635103\n",
      "Accuracy Top 5 0.770636\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Top 1 %f\" % (aciertosTop1/len(I)))\n",
    "print(\"Accuracy Top 5 %f\" % (aciertosTop5/len(I)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d7818-4a9b-488f-b9a4-6f93919523f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hf]",
   "language": "python",
   "name": "conda-env-.conda-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
